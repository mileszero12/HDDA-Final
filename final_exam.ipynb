{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "desirable-crest",
   "metadata": {},
   "source": [
    "# **Final Exam** \n",
    "### *Tan Yu*\n",
    "***\n",
    "`Here are some functions:`\n",
    "####  1.  *Import and preprocess the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liquid-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas\n",
    "import numpy as np\n",
    "import operator\n",
    "xtest = pandas.read_csv('bbb.test.csv', header = None)\n",
    "xtrain = pandas.read_csv('bbb.train.csv',header = None)\n",
    "ytest = pandas.read_csv('labels.test.csv',header = None)\n",
    "ytrain = pandas.read_csv('labels.train.csv',header = None)\n",
    "yytrain = ytrain.replace('nc', 1)\n",
    "fytrain = yytrain.replace('c', 0)\n",
    "yytest = ytest.replace('nc', 1)\n",
    "fytest = yytest.replace('c', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-berry",
   "metadata": {},
   "source": [
    "#### 2. *The Confusion Matrix Generator Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "honest-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionM(truey, prey):\n",
    "    v00, v01, v10, v11 = 0, 0, 0, 0\n",
    "    for i in range(len(truey)):\n",
    "        if truey[i] == 0:\n",
    "            if prey[i] == 0:\n",
    "                v00 += 1\n",
    "            else:\n",
    "                v10 += 1\n",
    "        else:\n",
    "            if prey[i] == 0:\n",
    "                v01 += 1\n",
    "            else:\n",
    "                v11 += 1\n",
    "    print('Confusion Matrix|', 'True c(0)', 'True nc(1)', 'Total')\n",
    "    print('  Predicc c(0)  |',  v00,'       ', v01,'       ', v00+v01)\n",
    "    print('  Predicc nc(1) |',  v10,'      ', v11,'      ', v10+v11)\n",
    "    print('  Total         |',  v10+v00,'      ', v11+v01,'      ', v10+v11+v00+v01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-springfield",
   "metadata": {},
   "source": [
    "#### 3.*The prediction function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "double-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictFunc(x, y, beta):\n",
    "    res = {}\n",
    "    res['error'] = 0\n",
    "    res['prey'] = []\n",
    "    res['truey'] = []\n",
    "    for i in range(x.shape[0]):\n",
    "        temp = x.iloc[i,:]\n",
    "        tempty = y.iloc[i,0]\n",
    "        temppy = PredOneRow(temp, beta)\n",
    "        res['prey'].append(temppy)\n",
    "        res['truey'].append(tempty)\n",
    "        if tempty != temppy:  \n",
    "            res['error'] += 1\n",
    "    res['accu'] = 1 - res['error'] / x.shape[0]\n",
    "    res['mse'] = res['error'] / x.shape[0]\n",
    "    return res\n",
    "\n",
    "def PredOneRow(x, beta):\n",
    "    x = np.hstack((np.ones((1)), x.T))\n",
    "    pre = pi_val(np.dot(x, beta))\n",
    "    if pre > 0.5:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-showcase",
   "metadata": {},
   "source": [
    "#### 4.*The function to obtain $\\pi_i$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improved-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pi_val(input):\n",
    "    output = 1 / (1 + np.exp(-input))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-broadway",
   "metadata": {},
   "source": [
    "***\n",
    "## Problem (a) : *Log-likelihood function*\n",
    "\\begin{align*}\n",
    "l(\\beta) & = \\log(L(\\beta)) = \\log(\\prod_{i = 1}^{p} \\pi_i^{y_i}(1-\\pi_i)^{1 - y_i}) = \\sum_{i = 1}^p y_i \\log(\\pi_i) + (1-y_i)\\log(1-\\pi_i) \\\\ & = \\sum_{i = 1}^{p} (y_i \\log(\\dfrac{e^{\\beta_0 + \\beta^Tx}}{1+e^{\\beta_0 + \\beta^Tx}}) + (1-y_i)\\log(\\dfrac{1}{1+e^{\\beta_0 + \\beta^Tx}})) \\\\& = \\sum_{i = 1}^p y_i(\\beta_0 + \\beta^Tx) - \\log(1 + e^{\\beta_0 + \\beta^Tx})\n",
    "\\end{align*}\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-assault",
   "metadata": {},
   "source": [
    "## Problem (b) : *Logistic Regression*\n",
    "\n",
    "### *(1) The gradient*\n",
    "The first-order partial derivatives of the log-likelihood for each $\\beta_k, k = 0, 1, 2, ...,n$:\n",
    "\\begin{align*}\n",
    "\\dfrac{\\partial l(\\beta)}{\\partial \\beta_k} = \\sum_{i=1}^p y_i x_{ik} - \\pi_i x_{ik} = \\sum_{i = 1}^p x_{ik}(y_i - \\pi_i)\n",
    "\\end{align*}\n",
    "\n",
    "### *(2) Run the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "neutral-incident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  [193.59324301 139.76977672  63.93317386  10.39628063  37.53354754\n",
      "  -4.08151957  53.50637824 -11.00744558  60.29613406  23.58543401\n",
      "  64.52870379  15.0074556   56.56387753  -3.67342168  31.13642746\n",
      "  -9.14865753  60.34606201 -10.11079168  49.58187773   1.72000861\n",
      "  26.52278717  22.90649261  24.00779042  -5.20985243  37.98660774\n",
      "  -0.68047677 126.45654626 -12.76578706  36.52087995  -5.20613991\n",
      "  18.99514317  11.67972428  30.00025865  16.08483339] \n",
      "\n",
      "Error Num: 27   Accuracy: 0.619718309859155 \n",
      "\n",
      "Confusion Matrix| True c(0) True nc(1) Total\n",
      "  Predicc c(0)  | 0         0         0\n",
      "  Predicc nc(1) | 27        44        71\n",
      "  Total         | 27        44        71\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "def GradientD(x, y, stepsize, iters):\n",
    "    beta = np.random.random_sample((x.shape[1],1))\n",
    "    for i in range(iters):\n",
    "        yy = pi_val(np.dot(x, beta))\n",
    "        ########################\n",
    "        grad = np.dot(x.T, y - yy)\n",
    "        beta = beta - stepsize*grad\n",
    "    return beta\n",
    "\n",
    "def LR(x, y, stepsize, iters):\n",
    "    x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "    beta = GradientD(x, y, stepsize, iters)\n",
    "    return beta\n",
    "\n",
    "def OutputFuncLo(beta, res):\n",
    "    print('Coefficient: ', beta.flatten(), '\\n')\n",
    "    print('Error Num:', res['error'], '  Accuracy:', res['accu'], '\\n')\n",
    "\n",
    "betaLo = LR(xtrain, fytrain, 0.01, 200)\n",
    "resLo = PredictFunc(xtest, fytest, betaLo)\n",
    "OutputFuncLo(betaLo, resLo)\n",
    "confusionM(resLo['truey'], resLo['prey'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-avatar",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-point",
   "metadata": {},
   "source": [
    "## Problem (c) : *Ridge Regression*\n",
    "### (1) *Cost Function* \n",
    "\\begin{align*}\n",
    "J(\\beta) = \\sum_{i=1}^p (y_i - x_i^T \\beta)^2 + \\lambda \\left\\| \\beta \\right\\|_2^2 \\end{align*}\n",
    "\n",
    "### (2) *Explain why we use Ridge regression*\n",
    "\n",
    "### (3) *Run the model*\n",
    "\n",
    " \\begin{align*}\\text{Gradient of Ridge Regression}:\\dfrac{\\partial J(\\beta)}{\\partial \\beta_k} = -2\\sum_{i=1}^p x_{ik}(y_i-\\pi_i) + \\lambda \\beta_k\\end{align*}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sunset-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:  [-5.28735203  3.40603659  2.09529647  0.29911712  3.4043022   1.48010192\n",
      "  0.45004933  2.91646998  2.0345149  -0.20697624 -1.69097149 -1.30529714\n",
      " -0.87222543  1.44371649  1.75939505  0.21519688  0.37980811  1.83126508\n",
      " -0.92971087 -0.56015074  0.42888689 -3.51177069  2.62428285  1.62463815\n",
      "  1.53425564  1.19754346 -3.50851375 -0.84882865  1.41354569  1.60194299\n",
      "  0.26196949 -0.66868446  0.08900893 -2.83205961] \n",
      "\n",
      "Accuracy:  0.8309859154929577  Best Lambda:  0.01 \n",
      "\n",
      "Confusion Matrix| True c(0) True nc(1) Total\n",
      "  Predicc c(0)  | 15         0         15\n",
      "  Predicc nc(1) | 12        44        56\n",
      "  Total         | 27        44        71\n"
     ]
    }
   ],
   "source": [
    "def GradientD3(x, y, stepsize, iters, lam3):\n",
    "    #beta = np.ones((x.shape[1],1))\n",
    "    beta = np.random.random_sample((x.shape[1],1)) # 34*1\n",
    "    for i in range(iters):\n",
    "        yy = pi_val(np.dot(x, beta))\n",
    "        grad = -2*np.dot(x.T, y - yy)+ lam3 * beta\n",
    "        #print(grad)\n",
    "        beta = beta - stepsize*grad\n",
    "    return beta\n",
    "\n",
    "def RR(x, y, stepsize, iters, lam3):\n",
    "    x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "    beta = GradientD3(x, y, stepsize, iters, lam3)\n",
    "    return beta\n",
    "\n",
    "def cvkfold(data, lamrange, k):\n",
    "    folds = np.array_split(data, k)\n",
    "    tempmse = np.zeros((len(lamrange), 1))\n",
    "    for i in range(k):\n",
    "        train = folds.copy()\n",
    "        test = folds[i]\n",
    "        del train[i]\n",
    "        \n",
    "        train = pandas.concat(train, sort=False)\n",
    "        #print(test.shape)\n",
    "        xtrain_train = train.iloc[:, :33]\n",
    "        #print(xtrain_train)\n",
    "        ytrain_train = train.iloc[:, 33:]\n",
    "        xtrain_test = test.iloc[:, :33]\n",
    "        ytrain_test = test.iloc[:, 33:]\n",
    "        \n",
    "        for lam3 in lamrange:\n",
    "            betatemp = RR(xtrain_train, ytrain_train, 0.01, 100, lam3)\n",
    "            restemp = PredictFunc(xtrain_test, ytrain_test, betatemp)\n",
    "            tempmse[lamrange.index(lam3)] += restemp['mse']\n",
    "    return tempmse/k # average mse\n",
    " \n",
    "def usebestlam(lambdapotential, xtrain, fytrain, xtest, fytest):\n",
    "    up = 100\n",
    "    index = 0\n",
    "    for i in range(len(lambdalist)):\n",
    "        if lambdalist[i] <= up:\n",
    "            up = lambdalist[i]\n",
    "            index = i\n",
    "    bestlam = lambdapotential[index]\n",
    "    beta1 = RR(xtrain, fytrain, 0.01, 100, bestlam)\n",
    "    res = PredictFunc(xtest, fytest, beta1)\n",
    "    print('Coefficient: ', beta1.flatten(), '\\n')\n",
    "    print('Accuracy: ', res['accu'], ' Best Lambda: ', bestlam, '\\n')\n",
    "    confusionM(res['truey'], res['prey'])\n",
    "    return res['accu'], bestlam\n",
    "\n",
    "lambdapotential = [0.03, 0.01, 10]\n",
    "data = pandas.concat([xtrain, fytrain.reindex(xtrain.index)], axis=1)\n",
    "lambdalist = cvkfold(data, lambdapotential, 5)\n",
    "#print(lambdalist)\n",
    "acc, lam = usebestlam(lambdapotential, xtrain, fytrain, xtest, fytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-furniture",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-respondent",
   "metadata": {},
   "source": [
    "## Problem (d) : *LASSO Regression*\n",
    "### (1) *Cost Function* \n",
    "\\begin{align*}\n",
    "J(\\beta) = \\sum_{i=1}^p (y_i - \\sum_{j=1}^nx_{ij} \\beta_j)^2 + \\lambda \\sum_{j=1}^n\\left| \\beta_j \\right| \\end{align*}\n",
    "\n",
    "### (2) *Explain why we use Lasso regression*\n",
    "\n",
    "### (3) *Run the model*\n",
    "1. Randomly set $\\beta^0$ for iteration 0\n",
    "2. For $k$th iteration:\n",
    "   * Compute gradient $\\nabla f(\\beta^{k-1})$\n",
    "   * Set $z = \\beta^{k-1} - \\frac{1}{\\text{step size}} \\nabla f(\\beta^{k-1})$\n",
    "   * $\\beta^k = sgn(z) \\max[\\left|z\\right|-\\frac{\\lambda}{\\text{step size}}, 0]$\n",
    " \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-animation",
   "metadata": {},
   "source": [
    "## Problem (e) : *Best Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-revision",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
